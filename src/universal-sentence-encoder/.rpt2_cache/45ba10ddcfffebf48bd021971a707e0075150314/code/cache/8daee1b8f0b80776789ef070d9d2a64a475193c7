{"code":"/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the 'License');\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an 'AS IS' BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport * as tslib_1 from \"tslib\";\r\nimport * as tfconv from '@tensorflow/tfjs-converter';\r\nimport * as tf from '@tensorflow/tfjs-core';\r\nimport { loadVocabulary, Tokenizer } from './tokenizer';\r\nexport { version } from './version';\r\nvar BASE_PATH = 'https://tfhub.dev/google/tfjs-model/universal-sentence-encoder-qa-ondevice/1';\r\n// Index in the vocab file that needs to be skipped.\r\nvar SKIP_VALUES = [0, 1, 2];\r\n// Offset value for skipped vocab index.\r\nvar OFFSET = 3;\r\n// Input tensor size limit.\r\nvar INPUT_LIMIT = 192;\r\n// Model node name for query.\r\nvar QUERY_NODE_NAME = 'input_inp_text';\r\n// Model node name for query.\r\nvar RESPONSE_CONTEXT_NODE_NAME = 'input_res_context';\r\n// Model node name for response.\r\nvar RESPONSE_NODE_NAME = 'input_res_text';\r\n// Model node name for response result.\r\nvar RESPONSE_RESULT_NODE_NAME = 'Final/EncodeResult/mul';\r\n// Model node name for query result.\r\nvar QUERY_RESULT_NODE_NAME = 'Final/EncodeQuery/mul';\r\n// Reserved symbol count for tokenizer.\r\nvar RESERVED_SYMBOLS_COUNT = 3;\r\n// Value for token padding\r\nvar TOKEN_PADDING = 2;\r\n// Start value for each token\r\nvar TOKEN_START_VALUE = 1;\r\nexport function loadQnA() {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var use;\r\n        return tslib_1.__generator(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0:\r\n                    use = new UniversalSentenceEncoderQnA();\r\n                    return [4 /*yield*/, use.load()];\r\n                case 1:\r\n                    _a.sent();\r\n                    return [2 /*return*/, use];\r\n            }\r\n        });\r\n    });\r\n}\r\nvar UniversalSentenceEncoderQnA = /** @class */ (function () {\r\n    function UniversalSentenceEncoderQnA() {\r\n    }\r\n    UniversalSentenceEncoderQnA.prototype.loadModel = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            return tslib_1.__generator(this, function (_a) {\r\n                return [2 /*return*/, tfconv.loadGraphModel(BASE_PATH, { fromTFHub: true })];\r\n            });\r\n        });\r\n    };\r\n    UniversalSentenceEncoderQnA.prototype.load = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a, model, vocabulary;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0: return [4 /*yield*/, Promise.all([\r\n                            this.loadModel(),\r\n                            loadVocabulary(BASE_PATH + \"/vocab.json?tfjs-format=file\")\r\n                        ])];\r\n                    case 1:\r\n                        _a = _b.sent(), model = _a[0], vocabulary = _a[1];\r\n                        this.model = model;\r\n                        this.tokenizer = new Tokenizer(vocabulary, RESERVED_SYMBOLS_COUNT);\r\n                        return [2 /*return*/];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    /**\r\n     *\r\n     * Returns a map of queryEmbedding and responseEmbedding\r\n     *\r\n     * @param input the ModelInput that contains queries and answers.\r\n     */\r\n    UniversalSentenceEncoderQnA.prototype.embed = function (input) {\r\n        var _this = this;\r\n        var embeddings = tf.tidy(function () {\r\n            var queryEncoding = _this.tokenizeStrings(input.queries, INPUT_LIMIT);\r\n            var responseEncoding = _this.tokenizeStrings(input.responses, INPUT_LIMIT);\r\n            if (input.contexts != null) {\r\n                if (input.contexts.length !== input.responses.length) {\r\n                    throw new Error('The length of response strings ' +\r\n                        'and context strings need to match.');\r\n                }\r\n            }\r\n            var contexts = input.contexts || [];\r\n            if (input.contexts == null) {\r\n                contexts.length = input.responses.length;\r\n                contexts.fill('');\r\n            }\r\n            var contextEncoding = _this.tokenizeStrings(contexts, INPUT_LIMIT);\r\n            var modelInputs = {};\r\n            modelInputs[QUERY_NODE_NAME] = queryEncoding;\r\n            modelInputs[RESPONSE_NODE_NAME] = responseEncoding;\r\n            modelInputs[RESPONSE_CONTEXT_NODE_NAME] = contextEncoding;\r\n            return _this.model.execute(modelInputs, [QUERY_RESULT_NODE_NAME, RESPONSE_RESULT_NODE_NAME]);\r\n        });\r\n        var queryEmbedding = embeddings[0];\r\n        var responseEmbedding = embeddings[1];\r\n        return { queryEmbedding: queryEmbedding, responseEmbedding: responseEmbedding };\r\n    };\r\n    UniversalSentenceEncoderQnA.prototype.tokenizeStrings = function (strs, limit) {\r\n        var _this = this;\r\n        var tokens = strs.map(function (s) { return _this.shiftTokens(_this.tokenizer.encode(s), INPUT_LIMIT); });\r\n        return tf.tensor2d(tokens, [strs.length, INPUT_LIMIT], 'int32');\r\n    };\r\n    UniversalSentenceEncoderQnA.prototype.shiftTokens = function (tokens, limit) {\r\n        tokens.unshift(TOKEN_START_VALUE);\r\n        for (var index = 0; index < limit; index++) {\r\n            if (index >= tokens.length) {\r\n                tokens[index] = TOKEN_PADDING;\r\n            }\r\n            else if (!SKIP_VALUES.includes(tokens[index])) {\r\n                tokens[index] += OFFSET;\r\n            }\r\n        }\r\n        return tokens.slice(0, limit);\r\n    };\r\n    return UniversalSentenceEncoderQnA;\r\n}());\r\nexport { UniversalSentenceEncoderQnA };\r\n//# sourceMappingURL=use_qna.js.map","map":"{\"version\":3,\"file\":\"use_qna.js\",\"sourceRoot\":\"\",\"sources\":[\"src/use_qna.ts\"],\"names\":[],\"mappings\":\"AAAA;;;;;;;;;;;;;;;GAeG;;AAEH,OAAO,KAAK,MAAM,MAAM,4BAA4B,CAAC;AACrD,OAAO,KAAK,EAAE,MAAM,uBAAuB,CAAC;AAE5C,OAAO,EAAC,cAAc,EAAE,SAAS,EAAC,MAAM,aAAa,CAAC;AAEtD,OAAO,EAAC,OAAO,EAAC,MAAM,WAAW,CAAC;AAElC,IAAM,SAAS,GACX,8EAA8E,CAAC;AACnF,oDAAoD;AACpD,IAAM,WAAW,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;AAC9B,wCAAwC;AACxC,IAAM,MAAM,GAAG,CAAC,CAAC;AACjB,2BAA2B;AAC3B,IAAM,WAAW,GAAG,GAAG,CAAC;AACxB,6BAA6B;AAC7B,IAAM,eAAe,GAAG,gBAAgB,CAAC;AACzC,6BAA6B;AAC7B,IAAM,0BAA0B,GAAG,mBAAmB,CAAC;AACvD,gCAAgC;AAChC,IAAM,kBAAkB,GAAG,gBAAgB,CAAC;AAC5C,uCAAuC;AACvC,IAAM,yBAAyB,GAAG,wBAAwB,CAAC;AAC3D,oCAAoC;AACpC,IAAM,sBAAsB,GAAG,uBAAuB,CAAC;AACvD,uCAAuC;AACvC,IAAM,sBAAsB,GAAG,CAAC,CAAC;AACjC,0BAA0B;AAC1B,IAAM,aAAa,GAAG,CAAC,CAAC;AACxB,6BAA6B;AAC7B,IAAM,iBAAiB,GAAG,CAAC,CAAC;AAa5B,MAAM,UAAgB,OAAO;;;;;;oBACrB,GAAG,GAAG,IAAI,2BAA2B,EAAE,CAAC;oBAC9C,qBAAM,GAAG,CAAC,IAAI,EAAE,EAAA;;oBAAhB,SAAgB,CAAC;oBACjB,sBAAO,GAAG,EAAC;;;;CACZ;AAED;IAAA;IAyEA,CAAC;IArEO,+CAAS,GAAf;;;gBACE,sBAAO,MAAM,CAAC,cAAc,CAAC,SAAS,EAAE,EAAC,SAAS,EAAE,IAAI,EAAC,CAAC,EAAC;;;KAC5D;IAEK,0CAAI,GAAV;;;;;4BAC8B,qBAAM,OAAO,CAAC,GAAG,CAAC;4BAC5C,IAAI,CAAC,SAAS,EAAE;4BAChB,cAAc,CAAI,SAAS,iCAA8B,CAAC;yBAC3D,CAAC,EAAA;;wBAHI,KAAsB,SAG1B,EAHK,KAAK,QAAA,EAAE,UAAU,QAAA;wBAKxB,IAAI,CAAC,KAAK,GAAG,KAAK,CAAC;wBACnB,IAAI,CAAC,SAAS,GAAG,IAAI,SAAS,CAAC,UAAU,EAAE,sBAAsB,CAAC,CAAC;;;;;KACpE;IAED;;;;;OAKG;IACH,2CAAK,GAAL,UAAM,KAAiB;QAAvB,iBA8BC;QA7BC,IAAM,UAAU,GAAG,EAAE,CAAC,IAAI,CAAC;YACzB,IAAM,aAAa,GAAG,KAAI,CAAC,eAAe,CAAC,KAAK,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;YACvE,IAAM,gBAAgB,GAClB,KAAI,CAAC,eAAe,CAAC,KAAK,CAAC,SAAS,EAAE,WAAW,CAAC,CAAC;YACvD,IAAI,KAAK,CAAC,QAAQ,IAAI,IAAI,EAAE;gBAC1B,IAAI,KAAK,CAAC,QAAQ,CAAC,MAAM,KAAK,KAAK,CAAC,SAAS,CAAC,MAAM,EAAE;oBACpD,MAAM,IAAI,KAAK,CACX,iCAAiC;wBACjC,oCAAoC,CAAC,CAAC;iBAC3C;aACF;YACD,IAAM,QAAQ,GAAa,KAAK,CAAC,QAAQ,IAAI,EAAE,CAAC;YAChD,IAAI,KAAK,CAAC,QAAQ,IAAI,IAAI,EAAE;gBAC1B,QAAQ,CAAC,MAAM,GAAG,KAAK,CAAC,SAAS,CAAC,MAAM,CAAC;gBACzC,QAAQ,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;aACnB;YACD,IAAM,eAAe,GAAG,KAAI,CAAC,eAAe,CAAC,QAAQ,EAAE,WAAW,CAAC,CAAC;YACpE,IAAM,WAAW,GAA+B,EAAE,CAAC;YACnD,WAAW,CAAC,eAAe,CAAC,GAAG,aAAa,CAAC;YAC7C,WAAW,CAAC,kBAAkB,CAAC,GAAG,gBAAgB,CAAC;YACnD,WAAW,CAAC,0BAA0B,CAAC,GAAG,eAAe,CAAC;YAE1D,OAAO,KAAI,CAAC,KAAK,CAAC,OAAO,CACrB,WAAW,EAAE,CAAC,sBAAsB,EAAE,yBAAyB,CAAC,CAAC,CAAC;QACxE,CAAC,CAAgB,CAAC;QAClB,IAAM,cAAc,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QACrC,IAAM,iBAAiB,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAExC,OAAO,EAAC,cAAc,gBAAA,EAAE,iBAAiB,mBAAA,EAAC,CAAC;IAC7C,CAAC;IAEO,qDAAe,GAAvB,UAAwB,IAAc,EAAE,KAAa;QAArD,iBAIC;QAHC,IAAM,MAAM,GACR,IAAI,CAAC,GAAG,CAAC,UAAA,CAAC,IAAI,OAAA,KAAI,CAAC,WAAW,CAAC,KAAI,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,EAAvD,CAAuD,CAAC,CAAC;QAC3E,OAAO,EAAE,CAAC,QAAQ,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,MAAM,EAAE,WAAW,CAAC,EAAE,OAAO,CAAC,CAAC;IAClE,CAAC;IAEO,iDAAW,GAAnB,UAAoB,MAAgB,EAAE,KAAa;QACjD,MAAM,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC;QAClC,KAAK,IAAI,KAAK,GAAG,CAAC,EAAE,KAAK,GAAG,KAAK,EAAE,KAAK,EAAE,EAAE;YAC1C,IAAI,KAAK,IAAI,MAAM,CAAC,MAAM,EAAE;gBAC1B,MAAM,CAAC,KAAK,CAAC,GAAG,aAAa,CAAC;aAC/B;iBAAM,IAAI,CAAC,WAAW,CAAC,QAAQ,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE;gBAC/C,MAAM,CAAC,KAAK,CAAC,IAAI,MAAM,CAAC;aACzB;SACF;QACD,OAAO,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;IAChC,CAAC;IACH,kCAAC;AAAD,CAAC,AAzED,IAyEC\"}","dts":{"name":"/Users/igorstojanov/code/evaluations/tfjs-models/universal-sentence-encoder/use_qna.d.ts","writeByteOrderMark":false,"text":"/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the 'License');\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an 'AS IS' BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport * as tfconv from '@tensorflow/tfjs-converter';\r\nimport * as tf from '@tensorflow/tfjs-core';\r\nexport { version } from './version';\r\nexport interface ModelOutput {\r\n    queryEmbedding: tf.Tensor;\r\n    responseEmbedding: tf.Tensor;\r\n}\r\nexport interface ModelInput {\r\n    queries: string[];\r\n    responses: string[];\r\n    contexts?: string[];\r\n}\r\nexport declare function loadQnA(): Promise<UniversalSentenceEncoderQnA>;\r\nexport declare class UniversalSentenceEncoderQnA {\r\n    private model;\r\n    private tokenizer;\r\n    loadModel(): Promise<tfconv.GraphModel>;\r\n    load(): Promise<void>;\r\n    /**\r\n     *\r\n     * Returns a map of queryEmbedding and responseEmbedding\r\n     *\r\n     * @param input the ModelInput that contains queries and answers.\r\n     */\r\n    embed(input: ModelInput): ModelOutput;\r\n    private tokenizeStrings;\r\n    private shiftTokens;\r\n}\r\n"}}
